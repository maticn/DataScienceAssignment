filePath = "Data_Car_accidents_196.csv"
data <- read.csv(file=filePath, header=TRUE, sep=";", stringsAsFactors = TRUE)
data <- data[,2:6]  # remove IDs
data$Gender <- as.factor(data$Gender)
data$Accident <- as.factor(data$Accident)
data$Socioeconomic_status <- as.factor(data$Socioeconomic_status)
summary(data)
plot(data$Age, data$BAC, main="Age and BAC Scatter Plot",
xlab="Age", ylab="BAC", col=data$Accident, pch=19)
getBetas <- function(logistic_model) {
betas <- c()
for (i in 1:length(logistic_model$coefficients)) {
betas <- c(betas, logistic_model$coefficients[i])
}
return (betas)
}
getOddsRatios <- function(betas) {
oddsRatios <- c()
for (i in 1:length(betas)) {
oddsRatios <- c(oddsRatios, exp(betas[i]))
}
return (oddsRatios)
}
getStandardErrors <- function(logistic_model) {
standardErrors <- c()
for (i in 1:length(summary(logistic_model)$coefficients[, 2])) {
standardErrors <- c(standardErrors, summary(logistic_model)$coefficients[, 2][i])
}
return (standardErrors)
}
getBounds <- function(oddsRatios, betas, standardErrors, confidence_number = 1.96) {
bounds <- data.frame()
for (i in 1:length(betas)) {
low_bound <- exp(betas[i] - confidence_number * standardErrors[i])
high_bound <- exp(betas[i] + confidence_number * standardErrors[i])
entry <- data.frame(OR = oddsRatios[i], LB = low_bound, HB = high_bound, beta = betas[i], SE = standardErrors[i])
bounds <- rbind(bounds, entry)
}
return (bounds)
}
plotBounds <- function(bounds, numf_of_columns_from_bounds = 3) {
zeros <- rep(0, numf_of_columns_from_bounds)
num_of_plots <- nrow(bounds)
attach(mtcars)
par(mfrow=c(num_of_plots, 1)) # number of rows and columns on the same graph
for (i in 1:nrow(bounds)) {
dots <- as.numeric(bounds[i,1:numf_of_columns_from_bounds])
plot(dots, zeros, main=rownames(bounds)[i])
#boxplot(dots)
}
}
forestPlot <- function(df, boxLabels, yAxis, modelTitle) {
#dev.off()
p <- ggplot(df, aes(x = boxOdds, y = yAxis))
p + geom_vline(aes(xintercept = 1), size = .25, linetype = "dashed") +
geom_errorbarh(aes(xmax = boxCIHigh, xmin = boxCILow), size = .5, height = .2, color = "gray50") +
geom_point(size = 3.5, color = "orange") +
theme_bw() +
theme(panel.grid.minor = element_blank()) +
scale_y_continuous(breaks = yAxis, labels = boxLabels) +
scale_x_continuous(breaks = seq(0,270,10) ) +
#coord_trans(x = "log10") +
ylab("") +
xlab("Odds ratio (log scale)") +
#annotate(geom = "text", y =1.1, x = 3.5, label ="Model p < 0.001\nPseudo R^2 = 0.10", size = 3.5, hjust = 0) +
ggtitle(modelTitle)
}
onlyAccidents <- data[data$Acciden == 1, ]
gender <- data[data$Gender == 1, ]
median(1,2,3,4,5)
mean(1,2,3,4,5)
library(ISLR)
library(caret)
library(car)
library(MASS)
set.seed(7)
data <- Boston
median_crim_rate <- median(data$crim)
classFromCrimRate <- function(x) {
if (x > median_crim_rate) return (1)
else return (0)
}
calculatedClass <- sapply(data$crim, classFromCrimRate)
data$Class <- calculatedClass
data$Class <- as.factor(data$Class)
data <- data[,-1]
nrow(data[data$Class == 1,])
TrainingDataIndex <- createDataPartition(data$Class, p=0.75, list=FALSE)
trainingData <- data[TrainingDataIndex,]
testData <- data[-TrainingDataIndex,]
trainingLabels <- trainingData$Class
testLabels <- testData$Class
testDataWithoutClass <- testData[,-14]
prop.table(table(trainingLabels))
nearZeroVariables <- nearZeroVar(trainingData, saveMetrics = TRUE)
correlations <- cor(trainingData[,-14])
highCorrelations <- findCorrelation(correlations, cutoff = 0.75)
View(nearZeroVariables)
View(correlations)
nearZeroVariables <- nearZeroVar(trainingData, saveMetrics = TRUE)
correlations <- cor(trainingData[,-14])
highCorrelations <- findCorrelation(correlations, cutoff = 0.75)
trainingDataCorr <- trainingData[,-drop(c(4,9))]
testDataCorr <- testData[,-drop(c(4,9))]
testDataCorrWithoutClass <- testDataCorr[,-12]
lr_model_all <- train(Class~., data=trainingData,
method='glm', family=binomial(link='logit'),
preProcess=c('scale', 'center'))
lr_pred_all <- predict(lr_model_all, testData[,-14])
confusionMatrix(lr_pred_all, testData$Class)
lr_model_corr <- train(Class ~ rad + nox,
data=trainingData,
method='glm', family=binomial(link='logit'),
preProcess=c('scale', 'center'))
lr_pred_corr <- predict(lr_model_corr, testData[,-14])
confusionMatrix(lr_pred_corr, testData$Class)
vif(lr_model_corr$finalModel)
lr_model_all <- train(Class~., data=trainingData,
method='glm', family=binomial(link='logit'),
preProcess=c('scale', 'center'))
lr_pred_all <- predict(lr_model_all, testData[,-14])
confusionMatrix(lr_pred_all, testData$Class)
lr_model_all
confusionMatrix(lr_pred_all, testData$Class)
lr_model_corr <- train(Class ~ rad + nox,
data=trainingData,
method='glm', family=binomial(link='logit'),
preProcess=c('scale', 'center'))
lr_pred_corr <- predict(lr_model_corr, testData[,-14])
confusionMatrix(lr_pred_corr, testData$Class)
lr_model_corr
knnGrid <- expand.grid(.k=c(2))
knn_model_all <- train(x=trainingData[,-14], method='knn',
y=trainingData$Class,
preProcess=c('center', 'scale'),
tuneGrid = knnGrid)
knn_model_all
-6 + 0.05*40 + 1*3.5
exp(-0.5)
